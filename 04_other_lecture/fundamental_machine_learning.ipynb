{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled130.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02acSnBAdasH"
      },
      "source": [
        "Ref. Lecture material by Dr. Y. Kawanishi \n",
        "\n",
        "Adjusting for google colab "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkXE58ODVq8i"
      },
      "source": [
        "# Character recognition on Support Vector Machine (SVM) \n",
        "Handwriting recognition using the MNIST dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkP-_AzlWEHb",
        "outputId": "370cdc89-d906-4aba-8dc8-0d1d9941d00b"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvzCm7vBVoH7"
      },
      "source": [
        "#from sklearn.datasets import fetch_mldata # version <= 0.21\n",
        "from sklearn.datasets import fetch_openml # version >= 0.22\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjyU2-UIXTHe"
      },
      "source": [
        "#from sklearn.svm import LinearSVC as Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier as Classifier\n",
        "#from sklearn.ensemble import AdaBoostClassifier as Classifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw-uJlQpXPVY"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTCWwj0jWHkd"
      },
      "source": [
        "#mnist = fetch_mldata(\"MNIST original\", data_home=\".\")\n",
        "mnist_X, mnist_y = fetch_openml('mnist_784', version=1, data_home=\".\", return_X_y=True)\n",
        "#data = np.asarray(mnist.data, np.float32)\n",
        "x_all = mnist_X.astype(np.float32) / 255\n",
        "y_all = mnist_y.astype(np.int32)\n",
        "#data_train, data_test, label_train, label_test = train_test_split(data, mnist.target, test_size=0.2)\n",
        "data_train, data_test, label_train, label_test = train_test_split(x_all,y_all, test_size=0.2, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhrwNi1-WLC6",
        "outputId": "1b508c49-7cc7-4723-8c5b-a92060b27be2"
      },
      "source": [
        "classifier = Classifier()\n",
        "classifier.fit(data_train, label_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmE3lrhWNOP"
      },
      "source": [
        "result = classifier.predict(data_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx-IGdYEWOpc",
        "outputId": "c05248ab-e536-42c9-a670-1b56f3a383cf"
      },
      "source": [
        "cmat = confusion_matrix(label_test, result)\n",
        "print(cmat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1325    0    5    1    1    0    3    2    5    1]\n",
            " [   0 1580    3    8    2    1    0    3    2    1]\n",
            " [   4    3 1337    2    2    2    8    9   10    3]\n",
            " [   1    0   28 1357    0   10    0   19   10    8]\n",
            " [   1    0    3    0 1251    0    5    4    2   29]\n",
            " [   3    3    1   18    3 1222    9    1   10    3]\n",
            " [   3    1    0    0    4    9 1376    0    3    0]\n",
            " [   2    5   19    0    6    0    0 1454    3   14]\n",
            " [   0    6   11   15    5    8    4    4 1294   10]\n",
            " [   6    6    4   17   18    4    1   12    7 1345]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIv6Ya21WSiw",
        "outputId": "695762d0-5b87-410b-a801-95d40113153c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = accuracy_score(label_test, result)\n",
        "print(acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9672142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRfpBzrqWTpp"
      },
      "source": [
        "# Confirmation of characters \n",
        "One piece of MNIST data can be converted to image data by passing through the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZppoxBWQWfU7"
      },
      "source": [
        "def to_image(feat):\n",
        "    return feat.reshape(28, 28)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUo-CUbPWi8C"
      },
      "source": [
        "img = to_image(data_test[50])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfJvGlsGWzoV"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vztk4t4xW2vw",
        "outputId": "4e22a22a-5d0b-460d-a1ef-fb9a4d0dca66"
      },
      "source": [
        "plt.imshow(img, cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paLS1WqRW9h-",
        "outputId": "4470377f-5c58-4883-948e-64f8dcf18021"
      },
      "source": [
        "classifier.predict([data_test[50]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNp3xOkXj28"
      },
      "source": [
        "\n",
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPzuE9pKXmVW"
      },
      "source": [
        "#from sklearn.datasets import fetch_mldata # version <= 0.21\n",
        "from sklearn.datasets import fetch_openml # version >= 0.22\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC8LWhq2XpQE"
      },
      "source": [
        "#mnist = fetch_mldata(\"MNIST original\", data_home=\".\")\n",
        "mnist_X, mnist_y = fetch_openml('mnist_784', version=1, data_home=\".\", return_X_y=True)\n",
        "#data = np.asarray(mnist.data, np.float32)\n",
        "x_all = mnist_X.astype(np.float32) / 255\n",
        "y_all = mnist_y.astype(np.int32)\n",
        "#data_train, data_test, label_train, label_test = train_test_split(data, mnist.target, test_size=0.2)\n",
        "data_train, data_test, label_train, label_test = train_test_split(x_all,y_all, test_size=0.2, random_state=42)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2etj2IywXrwi"
      },
      "source": [
        "label_train_category = to_categorical(label_train)\n",
        "label_test_category = to_categorical(label_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArAqvnhcXuVT"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(100, input_dim=784))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "fy7Q4VYRXxCy",
        "outputId": "4c293413-5255-4ba8-82f4-6ea70e5d124f"
      },
      "source": [
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "model.fit(data_train, label_train_category, epochs=20, batch_size=100, validation_split=0.1, verbose=0, callbacks=[TQDMNotebookCallback(leave_inner=True)])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-33c9a175342e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleave_inner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tqdm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvD1OpuqX0PV"
      },
      "source": [
        "result = model.predict_classes(data_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbOtsTCGX25I"
      },
      "source": [
        "cmat = confusion_matrix(label_test, result)\n",
        "print(cmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb1gGrR1X5Sk"
      },
      "source": [
        "Change the parameters to see the difference in recognition rate "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3lmhUPYIwK"
      },
      "source": [
        "\n",
        "\n",
        "*   Try increasing the number of learning: change epoch \n",
        "*   Try increasing the number of units in the network layer (try increasing the value in Dense () below)\n",
        "\n",
        "  model.add(Dense(10)) -> model.add(Dense(100))\n",
        "*   Try increasing the network layer (add code like the following) \n",
        "  model.add(Dense(100))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "Point\n",
        "*   Start with a simple model \n",
        "*   Training data loss does not decrease (accuracy does not increase) \n",
        "　　It's not enough to classify, so let's complicate the model.\"Increase the number of units\" or \"Increase layers\"\n",
        "*   The loss of training data does not decrease easily \n",
        "  Model can be too complex.\"Reduce the number of units\" or \"Reduce layers \"\n",
        "*   The accuracy of the training data is high, but the accuracy of the test data is low. \n",
        "  There may be insufficient training data. \"Increase data\" or \"Simplify the model\"\n",
        "*   Although the loss of training data is low, the loss of test data increases steadily. \n",
        "  Overfitting. \"Reduce the number of units\" or \"Reduce layers\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-9o5VPoZzkz"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "Perform CNN that captures data as an image and simultaneously performs image feature extraction and recognition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y-3uPuSauPa"
      },
      "source": [
        "#from sklearn.datasets import fetch_mldata # version <= 0.21\n",
        "from sklearn.datasets import fetch_openml # version >= 0.22\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqLpwkpLav6F"
      },
      "source": [
        "#mnist = fetch_mldata(\"MNIST original\", data_home=\".\")\n",
        "mnist_X, mnist_y = fetch_openml('mnist_784', version=1, data_home=\".\", return_X_y=True)\n",
        "#data = np.asarray(mnist.data, np.float32)\n",
        "x_all = mnist_X.astype(np.float32) / 255\n",
        "y_all = mnist_y.astype(np.int32)\n",
        "#data_train, data_test, label_train, label_test = train_test_split(data, mnist.target, test_size=0.2)\n",
        "data_train, data_test, label_train, label_test = train_test_split(x_all,y_all, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjCi02xQa7CU"
      },
      "source": [
        "def conv_feat_2_image(feats):\n",
        "    data = np.ndarray((len(feats), 28, 28, 1),\n",
        "                      dtype=np.float32)\n",
        "    for i, f in enumerate(feats):\n",
        "        data[i]=f.reshape(28,28,1)\n",
        "    return data\n",
        "\n",
        "train_images = conv_feat_2_image(data_train)\n",
        "test_images = conv_feat_2_image(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dqf2L1ya76v"
      },
      "source": [
        "label_train_category = to_categorical(label_train)\n",
        "label_test_category = to_categorical(label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RJACWiTa-oU"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='valid'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwceMPtybCye"
      },
      "source": [
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "model.fit(train_images, label_train_category, epochs=10, batch_size=100, validation_split=0.1, verbose=0, callbacks=[TQDMNotebookCallback(leave_inner=True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdoXtfcWbFuQ"
      },
      "source": [
        "result = model.predict_classes(test_images, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR4L5Ue1bHn1"
      },
      "source": [
        "cmat = confusion_matrix(label_test, result)\n",
        "print(cmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6om88kgbNSS"
      },
      "source": [
        "# Read and recognize your own image \n",
        "Create a folder called train in the My Documents folder, create folders 0, 1,… corresponding to each class under it, and put images in it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdyPPKvfbRHz"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKEkZrM3bayg"
      },
      "source": [
        "# Image loading function (reading all images in a folder) \n",
        "def load_images(inputpath):\n",
        "    imglist = []\n",
        "\n",
        "    for root, dirs, files in os.walk(inputpath):\n",
        "        for fn in sorted(files):\n",
        "            bn, ext = os.path.splitext(fn)\n",
        "            if ext not in [\".bmp\", \".jpg\", \".png\"]:\n",
        "                continue\n",
        "\n",
        "            filename = os.path.join(root, fn)\n",
        "            # Loading of evaluation image (32x32 size color image) \n",
        "            testimage = image.img_to_array(image.load_img(filename, target_size=(32, 32)))\n",
        "            imglist.append(testimage)\n",
        "    imgsdata = np.asarray(imglist, dtype=np.float32)\n",
        "\n",
        "    return imgsdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JsmS6Fvbjp2"
      },
      "source": [
        "# Load images from each class \n",
        "imgs0 = load_images(\"train/0\")\n",
        "imgs1 = load_images(\"train/1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6ayqMQnbvzN"
      },
      "source": [
        "# Make the corresponding label \n",
        "labels0 = [0] * len(imgs0)\n",
        "labels1 = [1] * len(imgs1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFkbajWwbwpq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky6k2ewObztb"
      },
      "source": [
        "# Normalize together \n",
        "data = np.vstack((imgs0, imgs1))\n",
        "data /= np.max(data)\n",
        "labels = labels0 + labels1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoop5wUOb72Q"
      },
      "source": [
        "train_images, test_images, label_train, label_test = train_test_split(data, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTD3sVWmb-Ar"
      },
      "source": [
        "label_train_category = to_categorical(label_train)\n",
        "label_test_category = to_categorical(label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITM93T-pb_R-"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3))) # ← カラー画像なので　3 x 32 x 32\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(500))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(100))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2)) # Output is 0 folder and 1 folder, so 2 classes \n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfcmMkEfcRG4"
      },
      "source": [
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "model.fit(train_images, label_train_category, epochs=10, batch_size=100, validation_split=0.1, verbose=0, callbacks=[TQDMNotebookCallback(leave_inner=True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UPtuLeWcTsh"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS9fseQBcW7r"
      },
      "source": [
        "plt.imshow(test_images[0])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlXZN0WjcZeX"
      },
      "source": [
        "# Check if it is recognized correctly\n",
        "model.predict_classes(np.asarray([test_images[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox7qLpNMce-t"
      },
      "source": [
        "# Use of trained model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovX0hBUcnL_"
      },
      "source": [
        "When using as it is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNIYBVwYcpmg"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "basemodel = VGG16(weights='imagenet',  include_top=True)\n",
        "basemodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHbhjqEXcror"
      },
      "source": [
        "# Image loading function (reading all images in a folder) \n",
        "def load_images_for_vgg16(inputpath):\n",
        "    imglist = []\n",
        "\n",
        "    for root, dirs, files in os.walk(inputpath):\n",
        "        for fn in sorted(files):\n",
        "            bn, ext = os.path.splitext(fn)\n",
        "            if ext not in [\".bmp\", \".jpg\", \".png\"]:\n",
        "                continue\n",
        "\n",
        "            filename = os.path.join(root, fn)\n",
        "            # Loading of evaluation image (224x224 size color image) \n",
        "            testimage = image.img_to_array(image.load_img(filename, target_size=(224,224)))\n",
        "            imglist.append(testimage)\n",
        "    imgsdata = np.asarray(imglist, dtype=np.float32)\n",
        "\n",
        "    return imgsdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDG8oXSjc3Yu"
      },
      "source": [
        "# Load images from each class \n",
        "imgs0 = load_images_for_vgg16(\"train/0\")\n",
        "imgs1 = load_images_for_vgg16(\"train/1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tO3V-Vkc66m"
      },
      "source": [
        "# Make the corresponding label \n",
        "labels0 = [0] * len(imgs0)\n",
        "labels1 = [1] * len(imgs1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1jHgvJGdBF7"
      },
      "source": [
        "data = np.vstack((imgs0, imgs1))\n",
        "labels = labels0 + labels1\n",
        "\n",
        "train_images, test_images, label_train, label_test = train_test_split(data, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYYjZyVFdDJ0"
      },
      "source": [
        "# Try to recognize the 0th image \n",
        "preds = basemodel.predict(preprocess_input(np.array([test_images[0]])))\n",
        "results = decode_predictions(preds, top=5)[0]\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbGHdIKrdIrL"
      },
      "source": [
        "# Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJ7AEYZdLGQ"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "basemodel = VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OldiXKPEdNdt"
      },
      "source": [
        "# Fix the original network so that it does not change \n",
        "for layer in basemodel.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKqhavTdTyv"
      },
      "source": [
        "x = basemodel.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=basemodel.input, outputs=[x])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl_oiwbLdWWK"
      },
      "source": [
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "model.fit(train_images, label_train_category, epochs=10, batch_size=100, validation_split=0.1, verbose=0, callbacks=[TQDMNotebookCallback(leave_inner=True)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}